
name: CD

on:
  push:
    branches: [ "main" ]
    # Prevent self-trigger from any generated/transient files, just in case
    paths-ignore:
      - 'infra/backend.hcl'
      - '**/*.tfstate*'
      - '**/*.log'
      - '**/.terraform/**'
  workflow_dispatch: {}

# Prevent parallel runs on the same branch and auto-cancel older runs
concurrency:
  group: cd-${{ github.ref }}
  cancel-in-progress: true

env:
  AWS_REGION: eu-north-1
  PROJECT_NAME: cafe
  TF_IN_AUTOMATION: 'true'
  TF_INPUT: 'false'

jobs:
  build-test-push-and-deploy:
    # Safety net: never run forever
    timeout-minutes: 60
    # Extra guard: do not run if the actor is the bot (prevents “self-push” loops)
    if: ${{ github.actor != 'github-actions[bot]' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
    
      - name: Set up QEMU (multi-arch)
        uses: docker/setup-qemu-action@v3
        
      - name: Set up Docker Buildx (multi-arch)
        uses: docker/setup-buildx-action@v3

      # 1) Configure AWS creds (Learner Lab secrets must be fresh)
      - name: Configure AWS credentials (temporary secrets)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      # 2) Preflight sanity (fail fast on bad creds or DNS/egress)
      - name: Who am I (AWS STS)
        run: aws sts get-caller-identity

      - name: DNS sanity for AWS endpoints
        run: |
          python - <<'PY'
          import socket
          for host in ["autoscaling.eu-north-1.amazonaws.com",
                       "ecr.eu-north-1.amazonaws.com",
                       "rds.eu-north-1.amazonaws.com",
                       "elasticloadbalancing.eu-north-1.amazonaws.com"]:
              print(host, "->", socket.gethostbyname(host))
          PY

      # 3) Compute backend names (per-account S3 + DynamoDB)
      - name: Compute backend names
        id: acct
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "ACCOUNT_ID=${ACCOUNT_ID}" >> $GITHUB_OUTPUT
          echo "BUCKET=${{ env.PROJECT_NAME }}-tfstate-${ACCOUNT_ID}" >> $GITHUB_OUTPUT
          echo "LOCK_TABLE=${{ env.PROJECT_NAME }}-tf-lock" >> $GITHUB_OUTPUT

      # 4) Ensure backend exists (idempotent; no commits)
      - name: Ensure backend S3 bucket exists
        run: |
          set -e
          if aws s3api head-bucket --bucket "${{ steps.acct.outputs.BUCKET }}" 2>/dev/null; then
            echo "Bucket exists: ${{ steps.acct.outputs.BUCKET }}"
          else
            if [ "${{ env.AWS_REGION }}" = "us-east-1" ]; then
              aws s3api create-bucket \
                --bucket "${{ steps.acct.outputs.BUCKET }}" \
                --region ${{ env.AWS_REGION }}
            else
              aws s3api create-bucket \
                --bucket "${{ steps.acct.outputs.BUCKET }}" \
                --region ${{ env.AWS_REGION }} \
                --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}
            fi
          fi

      - name: Ensure DynamoDB lock table exists
        run: |
          set -e
          if aws dynamodb describe-table --table-name "${{ steps.acct.outputs.LOCK_TABLE }}" >/dev/null 2>&1; then
            echo "Lock table exists: ${{ steps.acct.outputs.LOCK_TABLE }}"
          else
            aws dynamodb create-table \
              --table-name "${{ steps.acct.outputs.LOCK_TABLE }}" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region ${{ env.AWS_REGION }}
            aws dynamodb wait table-exists --table-name "${{ steps.acct.outputs.LOCK_TABLE }}"
            echo "Created lock table: ${{ steps.acct.outputs.LOCK_TABLE }}"
          fi

      - name: Write backend config file (no commit)
        run: |
          mkdir -p infra
          cat > infra/backend.hcl <<EOF
          bucket         = "${{ steps.acct.outputs.BUCKET }}"
          key            = "infra/${{ env.AWS_REGION }}/terraform.tfstate"
          region         = "${{ env.AWS_REGION }}"
          dynamodb_table = "${{ steps.acct.outputs.LOCK_TABLE }}"
          encrypt        = true
          EOF

      # 5) Login to ECR
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      # 6) Compute image tag = Git SHA
      - name: Compute image tag
        id: vars
        run: echo "sha=${GITHUB_SHA}" >> $GITHUB_OUTPUT

      # 7) Try build & push (skip if repo not yet created; TF will create it)
      - name: Try build & push (skip on first run if repo missing)
        id: prepush
        env:
          TAG: ${{ steps.vars.outputs.sha }}
        run: |
          set -e
          REPO_URI=$(aws ecr describe-repositories \
            --repository-names ${{ env.PROJECT_NAME }}-repo \
            --query 'repositories[0].repositoryUri' \
            --output text 2>/dev/null || echo "")
            echo "repo_uri=$REPO_URI" >> $GITHUB_OUTPUT
            if [ -n "$REPO_URI" ]; then
            echo "Will push to $REPO_URI"
          else
            echo "ECR repo not yet available; Terraform will create it."
          fi

      - name: Build & Push image (multi-arch) - pre-apply
        if: ${{ steps.prepush.outputs.repo_uri != '' }}
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: |
            ${{ steps.prepush.outputs.repo_uri }}:${{ steps.vars.outputs.sha }}

      # 8) Terraform (remote backend)
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
      
      - name: clean local terraform artifacts
        working-directory: infra
        run: |
          rm -rf .terraform .terraform.lock.hcl terraform.tfstate terraform.tfstate.backup
          ls -la

      - name: Terraform init
        working-directory: infra
        run: terraform init -backend-config=backend.hcl
      
      - name: Show backend config + state count (debug)
        working-directory: infra
        run: |
          echo "==== backend.hcl ===="
          cat backend.hcl
          echo "==== workspace ===="
          terraform workspace show || true
          echo "==== state list count ===="
          terraform state list || echo "NO_STATE"
      
      - name: Import existing RDS security group (idempotent)
        working-directory: infra
        run: |
          set -e
          AWS_REGION="${{ env.AWS_REGION }}"
          PROJECT_NAME="${{ env.PROJECT_NAME }}"
          SG_NAME="${PROJECT_NAME}-rds-sg"
          TF_ADDR='module.rds[0].aws_security_group.rds'

          # Only if RDS is enabled
          if ! grep -Eq '^\s*enable_rds\s*=\s*true\s*$' env/dev.tfvars; then
            echo "enable_rds is not true; skipping RDS SG import."
            exit 0
          fi

          # Find SG by name (no terraform outputs needed)
          SG_ID="$(aws ec2 describe-security-groups \
            --region "$AWS_REGION" \
            --filters "Name=group-name,Values=$SG_NAME" \
            --query "SecurityGroups[0].GroupId" \
            --output text 2>/dev/null || true)"

          if [ -n "$SG_ID" ] && [ "$SG_ID" != "None" ]; then
            echo "Found existing SG $SG_NAME -> $SG_ID"
            terraform state show "$TF_ADDR" >/dev/null 2>&1 || \
              terraform import -lock-timeout=5m "$TF_ADDR" "$SG_ID"
          else
            echo "No SG named $SG_NAME found; Terraform will create it."
          fi

      - name: Import RDS subnet group if it exists (idempotent)
        working-directory: infra
        run: |
          set -e
          AWS_REGION="${{ env.AWS_REGION }}"
          PROJECT_NAME="${{ env.PROJECT_NAME }}"

          if ! grep -Eq '^\s*enable_rds\s*=\s*true\s*$' env/dev.tfvars; then
            echo "enable_rds is not true; skipping subnet group import."
            exit 0
          fi

          VPC_ID="$(terraform output -raw vpc_id 2>/dev/null || true)"
          if [ -z "$VPC_ID" ]; then
            echo "ERROR: terraform output vpc_id not found. Add output \"vpc_id\" in infra/outputs.tf"
            exit 1
          fi

          VPC_PREFIX="$(echo "$VPC_ID" | cut -c1-8)"
          SUBNET_GROUP_NAME="${PROJECT_NAME}-db-subnets-${VPC_PREFIX}"

          if aws rds describe-db-subnet-groups --region "$AWS_REGION" --db-subnet-group-name "$SUBNET_GROUP_NAME" >/dev/null 2>&1; then
            echo "Subnet group exists in AWS: $SUBNET_GROUP_NAME"
            terraform state show 'module.rds[0].aws_db_subnet_group.this' >/dev/null 2>&1 || \
              terraform import 'module.rds[0].aws_db_subnet_group.this' "$SUBNET_GROUP_NAME"
          else
            echo "Subnet group not found; Terraform will create it."
          fi

      - name: Import RDS DB instance if it exists (idempotent)
        working-directory: infra
        run: |
          set -e
          AWS_REGION="${{ env.AWS_REGION }}"
          PROJECT_NAME="${{ env.PROJECT_NAME }}"

          if ! grep -Eq '^\s*enable_rds\s*=\s*true\s*$' env/dev.tfvars; then
            echo "enable_rds is not true; skipping DB instance import."
            exit 0
          fi

          VPC_ID="$(terraform output -raw vpc_id 2>/dev/null || true)"
          if [ -z "$VPC_ID" ]; then
            echo "ERROR: terraform output vpc_id not found. Add output \"vpc_id\" in infra/outputs.tf"
            exit 1
          fi

          VPC_PREFIX="$(echo "$VPC_ID" | cut -c1-8)"
          DB_ID="${PROJECT_NAME}-db-${VPC_PREFIX}"

          if aws rds describe-db-instances --region "$AWS_REGION" --db-instance-identifier "$DB_ID" >/dev/null 2>&1; then
            echo "DB instance exists in AWS: $DB_ID"
            terraform state show 'module.rds[0].aws_db_instance.this' >/dev/null 2>&1 || \
              terraform import 'module.rds[0].aws_db_instance.this' "$DB_ID"
          else
            echo "DB instance not found; Terraform will create it."
          fi

      - name: Import IAM resources if they exist (idempotent)
        working-directory: infra
        run: |
          set -e
          ROLE_NAME="${{ env.PROJECT_NAME }}-ec2-role"
          PROFILE_NAME="${{ env.PROJECT_NAME }}-ec2-profile"
          VARS="-var-file=env/dev.tfvars -var=image_tag=${{ steps.vars.outputs.sha }}"

          # Role
          if aws iam get-role --role-name "$ROLE_NAME" >/dev/null 2>&1; then
            terraform state show aws_iam_role.ec2_role >/dev/null 2>&1 || \
            terraform import $VARS aws_iam_role.ec2_role "$ROLE_NAME"
          fi

          # Instance profile
          if aws iam get-instance-profile --instance-profile-name "$PROFILE_NAME" >/dev/null 2>&1; then
            terraform state show aws_iam_instance_profile.ec2_profile >/dev/null 2>&1 || \
            terraform import $VARS aws_iam_instance_profile.ec2_profile "$PROFILE_NAME"
          fi

          # Attachments (import id = ROLE_NAME/POLICY_ARN)
          if aws iam get-role --role-name "$ROLE_NAME" >/dev/null 2>&1; then
            ECR_POLICY_ARN="arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
            SSM_POLICY_ARN="arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"

            attached_policies=$(aws iam list-attached-role-policies \
              --role-name "$ROLE_NAME" \
              --query 'AttachedPolicies[].PolicyArn' \
              --output text)

            if echo "$attached_policies" | grep -q "$ECR_POLICY_ARN"; then
              terraform state show aws_iam_role_policy_attachment.ec2_readonly >/dev/null 2>&1 || \
              terraform import $VARS aws_iam_role_policy_attachment.ec2_readonly "$ROLE_NAME/$ECR_POLICY_ARN"
            fi

            if echo "$attached_policies" | grep -q "$SSM_POLICY_ARN"; then
              terraform state show aws_iam_role_policy_attachment.ssm_readonly >/dev/null 2>&1 || \
              terraform import $VARS aws_iam_role_policy_attachment.ssm_readonly "$ROLE_NAME/$SSM_POLICY_ARN"
            fi
          fi
      
      - name: Check S3 state object
        run: |
          aws s3 ls "s3://${{ steps.acct.outputs.BUCKET }}/infra/terraform.tfstate" || true
          echo "Listing bucket root:"
          aws s3 ls "s3://${{ steps.acct.outputs.BUCKET }}/" || true

      # 9) One-time imports if named resources already exist in AWS
      - name: Import ECR repo if it exists (idempotent)
        working-directory: infra
        run: |
          set -e
          REPO_NAME="${{ env.PROJECT_NAME }}-repo"
          TF_ADDR="module.ecr.aws_ecr_repository.repo"

          if aws ecr describe-repositories --region ${{ env.AWS_REGION }} --repository-names "$REPO_NAME" >/dev/null 2>&1; then
            echo "ECR repo exists in AWS: $REPO_NAME"
            if terraform state show "$TF_ADDR" >/dev/null 2>&1; then
              echo "Repo already in Terraform state: $TF_ADDR"
            else
              echo "Importing $REPO_NAME into state at $TF_ADDR"
              terraform import -input=false -var-file=env/dev.tfvars "$TF_ADDR" "$REPO_NAME"
            fi
          else
            echo "ECR repo not found; Terraform will create it."
          fi

#      - name: Import RDS subnet group if it exists (idempotent)
#        working-directory: infra
#        run: |
#          set -e
#          if aws rds describe-db-subnet-groups --db-subnet-group-name ${{ env.PROJECT_NAME }}-db-subnets >/dev/null 2>&1; then
#            terraform state show 'module.rds.aws_db_subnet_group.this' >/dev/null 2>&1 || \
#            terraform import -input=false -var-file=env/dev.tfvars 'module.rds.aws_db_subnet_group.this' ${{ env.PROJECT_NAME }}-db-subnets
#          else
#            echo "DB subnet group not found; Terraform will create it."
#          fi


      # 10) Apply with bounded retries (handles transient DNS/egress)
      - name: Terraform apply (bounded retries)
        working-directory: infra
        run: |
          set -e
          for i in 1 2; do
            terraform plan \
              -var-file=env/dev.tfvars \
              -var="image_tag=${{ steps.vars.outputs.sha }}" \
              -input=false \
              -out=tfplan

            if terraform apply -input=false -auto-approve tfplan; then
              exit 0
            fi

            echo "Apply attempt $i failed; retrying in 30s..."
            sleep 30
          done
          echo "Apply failed after 2 attempts"
          exit 1

      - name: Ensure ECR repo exists (post-apply)
        run: |
          set -e
          REPO_NAME="${{ env.PROJECT_NAME }}-repo"
          aws ecr describe-repositories --region ${{ env.AWS_REGION }} --repository-names "$REPO_NAME" >/dev/null 2>&1 || \
          aws ecr create-repository --region ${{ env.AWS_REGION }} --repository-name "$REPO_NAME" >/dev/null
      
      - name: Read repo URI
        id: repouri
        working-directory: infra
        run: |
          set -e
          REPO_URI=$(terraform output -raw ecr_repository_url)
          echo "repo_uri=$REPO_URI" >> $GITHUB_OUTPUT

      # 12) Post-apply build & push
      - name: Post-apply build & push (multi-arch; ensure image present)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: |
            ${{ steps.repouri.outputs.repo_uri }}:${{ steps.vars.outputs.sha }}
            ${{ steps.repouri.outputs.repo_uri }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # 13) Terraform outputs
      - name: Terraform outputs (ALB DNS)
        working-directory: infra
        run: |
          terraform output || true
          echo "ALB DNS: $(terraform output -raw alb_dns || true)"


