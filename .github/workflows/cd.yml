
name: CD

on:
  push:
    branches: [ "main" ]
    # Prevent self-trigger from any generated/transient files, just in case
    paths-ignore:
      - 'infra/backend.hcl'
      - '**/*.tfstate*'
      - '**/*.log'
      - '**/.terraform/**'
  workflow_dispatch: {}

# Prevent parallel runs on the same branch and auto-cancel older runs
concurrency:
  group: cd-${{ github.ref }}
  cancel-in-progress: true

env:
  AWS_REGION: eu-north-1
  PROJECT_NAME: cafe

jobs:
  build-test-push-and-deploy:
    # Safety net: never run forever
    timeout-minutes: 60
    # Extra guard: do not run if the actor is the bot (prevents “self-push” loops)
    if: ${{ github.actor != 'github-actions[bot]' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
    
      - name: Set up QEMU (multi-arch)
        uses: docker/setup-qemu-action@v3
        
      - name: Set up Docker Buildx (multi-arch)
        uses: docker/setup-buildx-action@v3

      # 1) Configure AWS creds (Learner Lab secrets must be fresh)
      - name: Configure AWS credentials (temporary secrets)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      # 2) Preflight sanity (fail fast on bad creds or DNS/egress)
      - name: Who am I (AWS STS)
        run: aws sts get-caller-identity

      - name: DNS sanity for AWS endpoints
        run: |
          python - <<'PY'
          import socket
          for host in ["autoscaling.eu-north-1.amazonaws.com",
                       "ecr.eu-north-1.amazonaws.com",
                       "rds.eu-north-1.amazonaws.com",
                       "elasticloadbalancing.eu-north-1.amazonaws.com"]:
              print(host, "->", socket.gethostbyname(host))
          PY

      # 3) Compute backend names (per-account S3 + DynamoDB)
      - name: Compute backend names
        id: acct
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "ACCOUNT_ID=${ACCOUNT_ID}" >> $GITHUB_OUTPUT
          echo "BUCKET=${{ env.PROJECT_NAME }}-tfstate-${ACCOUNT_ID}" >> $GITHUB_OUTPUT
          echo "LOCK_TABLE=${{ env.PROJECT_NAME }}-tf-lock" >> $GITHUB_OUTPUT

      # 4) Ensure backend exists (idempotent; no commits)
      - name: Ensure backend S3 bucket exists
        run: |
          set -e
          if aws s3api head-bucket --bucket "${{ steps.acct.outputs.BUCKET }}" 2>/dev/null; then
            echo "Bucket exists: ${{ steps.acct.outputs.BUCKET }}"
          else
            if [ "${{ env.AWS_REGION }}" = "us-east-1" ]; then
              aws s3api create-bucket \
                --bucket "${{ steps.acct.outputs.BUCKET }}" \
                --region ${{ env.AWS_REGION }}
            else
              aws s3api create-bucket \
                --bucket "${{ steps.acct.outputs.BUCKET }}" \
                --region ${{ env.AWS_REGION }} \
                --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}
            fi
          fi

      - name: Ensure DynamoDB lock table exists
        run: |
          set -e
          if aws dynamodb describe-table --table-name "${{ steps.acct.outputs.LOCK_TABLE }}" >/dev/null 2>&1; then
            echo "Lock table exists: ${{ steps.acct.outputs.LOCK_TABLE }}"
          else
            aws dynamodb create-table \
              --table-name "${{ steps.acct.outputs.LOCK_TABLE }}" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region ${{ env.AWS_REGION }}
            aws dynamodb wait table-exists --table-name "${{ steps.acct.outputs.LOCK_TABLE }}"
            echo "Created lock table: ${{ steps.acct.outputs.LOCK_TABLE }}"
          fi

      - name: Write backend config file (no commit)
        run: |
          mkdir -p infra
          cat > infra/backend.hcl <<EOF
          bucket         = "${{ steps.acct.outputs.BUCKET }}"
          key            = "infra/terraform.tfstate"
          region         = "${{ env.AWS_REGION }}"
          dynamodb_table = "${{ steps.acct.outputs.LOCK_TABLE }}"
          encrypt        = true
          EOF

      # 5) Login to ECR
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      # 6) Compute image tag = Git SHA
      - name: Compute image tag
        id: vars
        run: echo "sha=${GITHUB_SHA}" >> $GITHUB_OUTPUT

      # 7) Try build & push (skip if repo not yet created; TF will create it)
      - name: Try build & push (skip on first run if repo missing)
        id: prepush
        env:
          TAG: ${{ steps.vars.outputs.sha }}
        run: |
          set -e
          REPO_URI=$(aws ecr describe-repositories \
            --repository-names ${{ env.PROJECT_NAME }}-repo \
            --query 'repositories[0].repositoryUri' \
            --output text 2>/dev/null || echo "")
            echo "repo_uri=$REPO_URI" >> $GITHUB_OUTPUT
            if [ -n "$REPO_URI" ]; then
            echo "Will push to $REPO_URI"
          else
            echo "ECR repo not yet available; Terraform will create it."
          fi

      - name: Build & Push image (multi-arch) - pre-apply
        if: ${{ steps.prepush.outputs.repo_uri != '' }}
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: |
            ${{ steps.prepush.outputs.repo_uri }}:${{ steps.vars.outputs.sha }}

      # 8) Terraform (remote backend)
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
      
      - name: clean local terraform artifacts
        working-directory: infra
        run: |
          rm -rf .terraform .terraform.lock.hcl terraform.tfstate terraform.tfstate.backup backend.tf
          ls -la

      - name: Terraform init
        working-directory: infra
        run: terraform init -backend-config=backend.hcl
      
      - name: Show backend config + state count (debug)
        working-directory: infra
        run: |
          echo "==== backend.hcl ===="
          cat backend.hcl
          echo "==== workspace ===="
          terraform workspace show || true
          echo "==== state list count ===="
          terraform state list || echo "NO_STATE"
      
      - name: Check S3 state object
        run: |
          aws s3 ls "s3://${{ steps.acct.outputs.BUCKET }}/infra/terraform.tfstate" || true
          echo "Listing bucket root:"
          aws s3 ls "s3://${{ steps.acct.outputs.BUCKET }}/" || true

      # 9) One-time imports if named resources already exist in AWS
      - name: Import ECR repo if it exists (idempotent)
        working-directory: infra
        run: |
          set -e
          if aws ecr describe-repositories --repository-names ${{ env.PROJECT_NAME }}-repo >/dev/null 2>&1; then
            terraform state show 'module.ecr.aws_ecr_repository.repo' >/dev/null 2>&1 || \
            terraform import -input=false -var-file=env/dev.tfvars 'module.ecr.aws_ecr_repository.repo' ${{ env.PROJECT_NAME }}-repo
          else
            echo "ECR repo not found; Terraform will create it."
          fi

#      - name: Import RDS subnet group if it exists (idempotent)
#        working-directory: infra
#        run: |
#          set -e
#          if aws rds describe-db-subnet-groups --db-subnet-group-name ${{ env.PROJECT_NAME }}-db-subnets >/dev/null 2>&1; then
#            terraform state show 'module.rds.aws_db_subnet_group.this' >/dev/null 2>&1 || \
#            terraform import -input=false -var-file=env/dev.tfvars 'module.rds.aws_db_subnet_group.this' ${{ env.PROJECT_NAME }}-db-subnets
#          else
#            echo "DB subnet group not found; Terraform will create it."
#          fi


      # 10) Apply with bounded retries (handles transient DNS/egress)
      - name: Terraform apply (bounded retries)
        working-directory: infra
        run: |
          set -e
          for i in 1 2; do
            terraform plan \
              -var-file=env/dev.tfvars \
              -var="image_tag=${{ steps.vars.outputs.sha }}" \
              -input=false \
              -out=tfplan

            if terraform apply -input=false -auto-approve tfplan; then
              exit 0
            fi

            echo "Apply attempt $i failed; retrying in 30s..."
            sleep 30
          done
          echo "Apply failed after 2 attempts"
          exit 1


      - name: Read repo URI
        id: repouri
        run: |
          set -e
          REPO_URI=$(aws ecr describe-repositories \
            --repository-names ${{ env.PROJECT_NAME }}-repo \
            --query 'repositories[0].repositoryUri' \
            --output text)
            echo "repo_uri=$REPO_URI" >> $GITHUB_OUTPUT

      # 12) Post-apply build & push
      - name: Post-apply build & push (multi-arch; ensure image present)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: |
            ${{ steps.repouri.outputs.repo_uri }}:${{ steps.vars.outputs.sha }}
            ${{ steps.repouri.outputs.repo_uri }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # 13) Terraform outputs
      - name: Terraform outputs (ALB DNS)
        working-directory: infra
        run: |
          terraform output || true
          echo "ALB DNS: $(terraform output -raw alb_dns || true)"


